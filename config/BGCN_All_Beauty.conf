[data]
min_seq_len = 5
max_seq_len = 50
k_transition = 2

[model]
batch_size = 32
hidden_dim = 128
gcn_layers = 2
layer_norm_eps = 1e-6

[train]
epochs = 1

[bre]
model_name = bert-base-uncased
max_length = 256
out_dim = 64
dropout = 0.1
freeze_bert = False
pooling = mean
normalize = True 